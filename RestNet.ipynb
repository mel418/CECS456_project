{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mel418/CECS456_project/blob/main/RestNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uEZaM6NHEUX6"
      },
      "outputs": [],
      "source": [
        "# Install kaggle and download dataset\n",
        "!pip install -q kaggle\n",
        "\n",
        "# Upload your kaggle.json file when prompted\n",
        "from google.colab import files\n",
        "files.upload()  # Upload kaggle.json\n",
        "\n",
        "# Setup kaggle credentials\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# Download and extract dataset\n",
        "!unzip -q animals10.zip -d /content/animals10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pGNsIpsBEmXr"
      },
      "outputs": [],
      "source": [
        "# Cell 2: Import Libraries\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ldpY_fIxEtBt"
      },
      "outputs": [],
      "source": [
        "# Cell 3: Custom Dataset Class\n",
        "class Animals10Dataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.classes = sorted([d for d in os.listdir(root_dir)\n",
        "                              if os.path.isdir(os.path.join(root_dir, d))])\n",
        "        self.class_to_idx = {cls_name: i for i, cls_name in enumerate(self.classes)}\n",
        "\n",
        "        # Build file list\n",
        "        self.samples = []\n",
        "        for class_name in self.classes:\n",
        "            class_dir = os.path.join(root_dir, class_name)\n",
        "            class_idx = self.class_to_idx[class_name]\n",
        "            for img_name in os.listdir(class_dir):\n",
        "                if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                    self.samples.append((os.path.join(class_dir, img_name), class_idx))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, label = self.samples[idx]\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "print(\"Dataset class defined!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pp5iKOqrEyIZ"
      },
      "outputs": [],
      "source": [
        "# Cell 4: Define Bottleneck Block for ResNet50\n",
        "class BottleneckBlock(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
        "        super(BottleneckBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3,\n",
        "                               stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv3 = nn.Conv2d(out_channels, out_channels * self.expansion,\n",
        "                               kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(out_channels * self.expansion)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "print(\"BottleneckBlock defined!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "By0zK89ME5vK"
      },
      "outputs": [],
      "source": [
        "# Cell 5: Define ResNet50 Architecture\n",
        "class ResNet50(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(ResNet50, self).__init__()\n",
        "        self.in_channels = 64\n",
        "\n",
        "        # Initial convolution\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        # Residual layers with Bottleneck blocks\n",
        "        self.layer1 = self._make_layer(BottleneckBlock, 64, 3)\n",
        "        self.layer2 = self._make_layer(BottleneckBlock, 128, 4, stride=2)\n",
        "        self.layer3 = self._make_layer(BottleneckBlock, 256, 6, stride=2)\n",
        "        self.layer4 = self._make_layer(BottleneckBlock, 512, 3, stride=2)\n",
        "\n",
        "        # Global average pooling and FC layer\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512 * BottleneckBlock.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, out_channels, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.in_channels != out_channels * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.in_channels, out_channels * block.expansion,\n",
        "                         kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels * block.expansion)\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
        "        self.in_channels = out_channels * block.expansion\n",
        "\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(block(self.in_channels, out_channels))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "print(\"ResNet50 architecture defined!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RLI_iSfPE9o4"
      },
      "outputs": [],
      "source": [
        "# Cell 6: Training and Validation Functions\n",
        "def train_model(model, train_loader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    # Add tqdm progress bar\n",
        "    pbar = tqdm(train_loader, desc='Training', leave=False)\n",
        "\n",
        "    for inputs, labels in pbar:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "        # Update progress bar with current metrics\n",
        "        pbar.set_postfix({\n",
        "            'loss': f'{loss.item():.4f}',\n",
        "            'acc': f'{100.*correct/total:.2f}%'\n",
        "        })\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    epoch_acc = 100 * correct / total\n",
        "\n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "def validate_model(model, val_loader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    # Add tqdm progress bar\n",
        "    pbar = tqdm(val_loader, desc='Validation', leave=False)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in pbar:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            # Update progress bar with current metrics\n",
        "            pbar.set_postfix({\n",
        "                'loss': f'{loss.item():.4f}',\n",
        "                'acc': f'{100.*correct/total:.2f}%'\n",
        "            })\n",
        "\n",
        "    epoch_loss = running_loss / len(val_loader)\n",
        "    epoch_acc = 100 * correct / total\n",
        "\n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "print(\"Training functions defined!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1HBeKHAPFBdC"
      },
      "outputs": [],
      "source": [
        "# Cell 7:\n",
        "num_epochs = 15\n",
        "batch_size = 64\n",
        "learning_rate = 0.01\n",
        "img_size = 128\n",
        "num_workers = 2\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"TRAINING CONFIGURATION\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Epochs: {num_epochs}\")\n",
        "print(f\"Batch Size: {batch_size}\")\n",
        "print(f\"Learning Rate: {learning_rate}\")\n",
        "print(f\"Image Size: {img_size}x{img_size}\")\n",
        "print(f\"Target: 50-60% accuracy\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_b_VhGBPFJAV"
      },
      "outputs": [],
      "source": [
        "# Cell 8: Load and Prepare Dataset\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\\n\")\n",
        "\n",
        "# Simplified data transformations for faster training\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((img_size, img_size)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                       std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((img_size, img_size)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                       std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "dataset_path = '/content/animals10/raw-img'\n",
        "\n",
        "print(\"Loading Animals10 dataset...\")\n",
        "full_dataset = Animals10Dataset(root_dir=dataset_path, transform=train_transform)\n",
        "\n",
        "num_classes = len(full_dataset.classes)\n",
        "print(f\"Number of classes: {num_classes}\")\n",
        "print(f\"Classes: {full_dataset.classes}\")\n",
        "print(f\"Total images: {len(full_dataset)}\")\n",
        "\n",
        "# Split dataset into train and validation (70/30 for faster training)\n",
        "train_size = int(0.7 * len(full_dataset))\n",
        "val_size = len(full_dataset) - train_size\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(\n",
        "    full_dataset, [train_size, val_size]\n",
        ")\n",
        "\n",
        "# Update validation dataset transform\n",
        "val_dataset.dataset.transform = test_transform\n",
        "\n",
        "print(f\"\\nTraining samples: {len(train_dataset)}\")\n",
        "print(f\"Validation samples: {len(val_dataset)}\")\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size,\n",
        "                         shuffle=True, num_workers=num_workers, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size,\n",
        "                       shuffle=False, num_workers=num_workers, pin_memory=True)\n",
        "\n",
        "print(f\"Train batches: {len(train_loader)}\")\n",
        "print(f\"Val batches: {len(val_loader)}\")\n",
        "print(\"\\nDataset loaded successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yZ-SgDWlFQzh"
      },
      "outputs": [],
      "source": [
        "# Cell 9: Initialize Model\n",
        "model = ResNet50(num_classes=num_classes).to(device)\n",
        "print(f\"Model: ResNet-50\")\n",
        "print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "print(f\"Input size: {img_size}x{img_size}\")\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=1e-4)\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
        "\n",
        "print(\"\\nModel initialized and ready to train!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SCmk4j4ua0iX"
      },
      "outputs": [],
      "source": [
        "# Cell 10: Training Loop\n",
        "train_losses, train_accs = [], []\n",
        "val_losses, val_accs = [], []\n",
        "best_val_acc = 0.0\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"STARTING TRAINING\")\n",
        "print(\"=\" * 60)\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    epoch_start = time.time()\n",
        "\n",
        "    train_loss, train_acc = train_model(model, train_loader, criterion, optimizer, device)\n",
        "    val_loss, val_acc = validate_model(model, val_loader, criterion, device)\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "    train_accs.append(train_acc)\n",
        "    val_losses.append(val_loss)\n",
        "    val_accs.append(val_acc)\n",
        "\n",
        "    epoch_time = time.time() - epoch_start\n",
        "    elapsed_time = time.time() - start_time\n",
        "\n",
        "    print(f\"\\nEpoch [{epoch+1}/{num_epochs}] - {epoch_time:.1f}s\")\n",
        "    print(f\"  Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
        "    print(f\"  Val Loss:   {val_loss:.4f} | Val Acc:   {val_acc:.2f}%\")\n",
        "    print(f\"  Elapsed Time: {elapsed_time/60:.1f} min\")\n",
        "\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        torch.save(model.state_dict(), 'resnet50_animals10_best.pth')\n",
        "        print(f\"  ‚úì New best model saved! (Val Acc: {val_acc:.2f}%)\")\n",
        "\n",
        "total_time = time.time() - start_time\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(f\"TRAINING COMPLETE!\")\n",
        "print(f\"Total Time: {total_time/60:.1f} minutes\")\n",
        "print(f\"Best Validation Accuracy: {best_val_acc:.2f}%\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2vV53CIBa2kv"
      },
      "outputs": [],
      "source": [
        "# Cell 11: Plot Training History\n",
        "plt.figure(figsize=(14, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(range(1, num_epochs+1), train_losses, 'b-o', label='Train Loss', linewidth=2)\n",
        "plt.plot(range(1, num_epochs+1), val_losses, 'r-s', label='Val Loss', linewidth=2)\n",
        "plt.xlabel('Epoch', fontsize=12)\n",
        "plt.ylabel('Loss', fontsize=12)\n",
        "plt.title('Training and Validation Loss', fontsize=14, fontweight='bold')\n",
        "plt.legend(fontsize=10)\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(range(1, num_epochs+1), train_accs, 'b-o', label='Train Acc', linewidth=2)\n",
        "plt.plot(range(1, num_epochs+1), val_accs, 'r-s', label='Val Acc', linewidth=2)\n",
        "plt.xlabel('Epoch', fontsize=12)\n",
        "plt.ylabel('Accuracy (%)', fontsize=12)\n",
        "plt.title('Training and Validation Accuracy', fontsize=14, fontweight='bold')\n",
        "plt.legend(fontsize=10)\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('resnet50_training_history.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nTraining history plot saved as 'resnet50_training_history.png'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Creating test dataset from validation set...\")\n",
        "\n",
        "# Re-split the dataset: 70% train, 15% validation, 15% test\n",
        "train_size = int(0.7 * len(full_dataset))\n",
        "val_size = int(0.15 * len(full_dataset))\n",
        "test_size = len(full_dataset) - train_size - val_size\n",
        "\n",
        "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(\n",
        "    full_dataset,\n",
        "    [train_size, val_size, test_size],\n",
        "    generator=torch.Generator().manual_seed(42)  # For reproducibility\n",
        ")\n",
        "\n",
        "# Apply test transform\n",
        "val_dataset.dataset.transform = test_transform\n",
        "test_dataset.dataset.transform = test_transform\n",
        "\n",
        "print(f\"üìä Dataset Split:\")\n",
        "print(f\"Training samples: {len(train_dataset)}\")\n",
        "print(f\"Validation samples: {len(val_dataset)}\")\n",
        "print(f\"Test samples: {len(test_dataset)}\")\n",
        "\n",
        "# Create test loader\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size,\n",
        "                         shuffle=False, num_workers=num_workers, pin_memory=True)\n",
        "\n",
        "print(f\"Test batches: {len(test_loader)}\")\n",
        "print(\"Test dataset created successfully!\")"
      ],
      "metadata": {
        "id": "Pmlh2ddBKcVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(model, test_loader, device):\n",
        "    \"\"\"Test the model and return predictions and true labels.\"\"\"\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    print(\"üß™ Testing Model...\")\n",
        "    pbar = tqdm(test_loader, desc='Testing')\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in pbar:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "            # Update progress bar\n",
        "            pbar.set_postfix({'acc': f'{100.*correct/total:.2f}%'})\n",
        "\n",
        "    test_acc = 100 * correct / total\n",
        "    return np.array(all_preds), np.array(all_labels), test_acc\n",
        "\n",
        "print(\"Test function defined!\")"
      ],
      "metadata": {
        "id": "joMSYbSgKeXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the best model\n",
        "model.load_state_dict(torch.load('resnet50_animals10_best.pth'))\n",
        "model.eval()\n",
        "\n",
        "# Get predictions\n",
        "predictions, true_labels, test_accuracy = test_model(model, test_loader, device)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"TEST RESULTS\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"üìä Test Accuracy: {test_accuracy:.2f}%\")\n",
        "print(f\"Best Validation Accuracy: {best_val_acc:.2f}%\")\n",
        "print(f\"Difference (Val - Test): {best_val_acc - test_accuracy:.2f}%\")\n",
        "print(\"=\" * 60)"
      ],
      "metadata": {
        "id": "I80rLCm-KmlR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = full_dataset.classes\n",
        "cm = confusion_matrix(true_labels, predictions)\n",
        "\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=class_names, yticklabels=class_names,\n",
        "            cbar_kws={'label': 'Count'})\n",
        "plt.xlabel('Predicted Label', fontsize=12)\n",
        "plt.ylabel('True Label', fontsize=12)\n",
        "plt.title('ResNet50 - Confusion Matrix', fontsize=14, fontweight='bold')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.yticks(rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.savefig('resnet50_confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nüîç Analyzing Most Confused Classes...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Find most confused pairs\n",
        "confused_pairs = []\n",
        "for i in range(len(class_names)):\n",
        "    for j in range(len(class_names)):\n",
        "        if i != j and cm[i][j] > 5:  # Threshold of 5 misclassifications\n",
        "            confused_pairs.append((class_names[i], class_names[j], cm[i][j]))\n",
        "\n",
        "# Sort by number of confusions\n",
        "confused_pairs.sort(key=lambda x: x[2], reverse=True)\n",
        "\n",
        "print(\"Most Confused Class Pairs (misclassified > 5 times):\")\n",
        "for true_class, pred_class, count in confused_pairs[:10]:  # Top 10\n",
        "    print(f\"  {true_class} ‚Üí {pred_class}: {count} times\")\n",
        "\n",
        "print(\"=\" * 60)"
      ],
      "metadata": {
        "id": "iY8huD6GKnPm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nüìã Classification Report:\")\n",
        "print(\"=\" * 70)\n",
        "report = classification_report(true_labels, predictions,\n",
        "                               target_names=class_names,\n",
        "                               digits=3)\n",
        "print(report)\n",
        "\n",
        "# Save report to file\n",
        "with open('resnet50_classification_report.txt', 'w') as f:\n",
        "    f.write(\"ResNet50 Classification Report\\n\")\n",
        "    f.write(\"=\" * 70 + \"\\n\\n\")\n",
        "    f.write(f\"Test Accuracy: {test_accuracy:.2f}%\\n\")\n",
        "    f.write(f\"Best Validation Accuracy: {best_val_acc:.2f}%\\n\\n\")\n",
        "    f.write(report)\n",
        "\n",
        "print(\"\\nClassification report saved to 'resnet50_classification_report.txt'\")"
      ],
      "metadata": {
        "id": "V8PPWK_ZKslw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate per-class accuracy\n",
        "class_correct = [0] * len(class_names)\n",
        "class_total = [0] * len(class_names)\n",
        "\n",
        "for pred, true in zip(predictions, true_labels):\n",
        "    class_total[true] += 1\n",
        "    if pred == true:\n",
        "        class_correct[true] += 1\n",
        "\n",
        "class_accuracy = [100 * c / t if t > 0 else 0\n",
        "                  for c, t in zip(class_correct, class_total)]\n",
        "\n",
        "# Create DataFrame for better visualization\n",
        "import pandas as pd\n",
        "accuracy_df = pd.DataFrame({\n",
        "    'Class': class_names,\n",
        "    'Accuracy (%)': class_accuracy,\n",
        "    'Correct': class_correct,\n",
        "    'Total': class_total\n",
        "})\n",
        "\n",
        "print(\"\\nüìä Per-Class Accuracy:\")\n",
        "print(\"=\" * 70)\n",
        "print(accuracy_df.to_string(index=False))\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Plot per-class accuracy\n",
        "plt.figure(figsize=(12, 6))\n",
        "bars = plt.bar(class_names, class_accuracy, color='skyblue', edgecolor='navy', linewidth=1.5)\n",
        "\n",
        "# Color bars based on performance\n",
        "for i, bar in enumerate(bars):\n",
        "    if class_accuracy[i] >= 80:\n",
        "        bar.set_color('green')\n",
        "        bar.set_alpha(0.7)\n",
        "    elif class_accuracy[i] >= 60:\n",
        "        bar.set_color('orange')\n",
        "        bar.set_alpha(0.7)\n",
        "    else:\n",
        "        bar.set_color('red')\n",
        "        bar.set_alpha(0.7)\n",
        "\n",
        "plt.xlabel('Animal Class', fontsize=12, fontweight='bold')\n",
        "plt.ylabel('Accuracy (%)', fontsize=12, fontweight='bold')\n",
        "plt.title('ResNet50 - Per-Class Accuracy', fontsize=14, fontweight='bold')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.ylim(0, 100)\n",
        "plt.axhline(y=test_accuracy, color='r', linestyle='--', linewidth=2,\n",
        "            label=f'Overall Accuracy: {test_accuracy:.2f}%')\n",
        "plt.legend()\n",
        "plt.grid(axis='y', alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig('resnet50_per_class_accuracy.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nPer-class accuracy plot saved!\")"
      ],
      "metadata": {
        "id": "bsmH9jMWKty-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nüî¨ DETAILED PERFORMANCE ANALYSIS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Best performing classes\n",
        "best_classes = sorted(zip(class_names, class_accuracy), key=lambda x: x[1], reverse=True)\n",
        "print(\"\\n‚úÖ Best Performing Classes:\")\n",
        "for i, (class_name, acc) in enumerate(best_classes[:3], 1):\n",
        "    print(f\"  {i}. {class_name}: {acc:.2f}%\")\n",
        "\n",
        "# Worst performing classes\n",
        "print(\"\\n‚ùå Worst Performing Classes:\")\n",
        "for i, (class_name, acc) in enumerate(reversed(best_classes[-3:]), 1):\n",
        "    print(f\"  {i}. {class_name}: {acc:.2f}%\")\n",
        "\n",
        "# Calculate precision, recall, f1 per class\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "precision, recall, f1, support = precision_recall_fscore_support(\n",
        "    true_labels, predictions, average=None\n",
        ")\n",
        "\n",
        "print(\"\\nüìà Detailed Metrics by Class:\")\n",
        "print(\"-\" * 70)\n",
        "print(f\"{'Class':<15} {'Precision':<12} {'Recall':<12} {'F1-Score':<12} {'Support':<10}\")\n",
        "print(\"-\" * 70)\n",
        "for i, class_name in enumerate(class_names):\n",
        "    print(f\"{class_name:<15} {precision[i]:<12.3f} {recall[i]:<12.3f} \"\n",
        "          f\"{f1[i]:<12.3f} {support[i]:<10}\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "# Overall metrics\n",
        "avg_precision = np.mean(precision)\n",
        "avg_recall = np.mean(recall)\n",
        "avg_f1 = np.mean(f1)\n",
        "\n",
        "print(f\"\\n{'Average':<15} {avg_precision:<12.3f} {avg_recall:<12.3f} {avg_f1:<12.3f}\")\n",
        "print(\"=\" * 70)"
      ],
      "metadata": {
        "id": "rbAxPjfKSagd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hsnxaHCJa45S"
      },
      "outputs": [],
      "source": [
        "# Cell 12: Save Final Model and Summary\n",
        "torch.save(model.state_dict(), 'resnet50_animals10_final.pth')\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"TRAINING SUMMARY\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Total Training Time: {total_time/60:.1f} minutes\")\n",
        "print(f\"Final Train Accuracy: {train_accs[-1]:.2f}%\")\n",
        "print(f\"Final Validation Accuracy: {val_accs[-1]:.2f}%\")\n",
        "print(f\"Best Validation Accuracy: {best_val_acc:.2f}%\")\n",
        "print(f\"\\nModels saved:\")\n",
        "print(f\"  - resnet50_animals10_best.pth (best val acc)\")\n",
        "print(f\"  - resnet50_animals10_final.pth (final epoch)\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"RESNET50 - FINAL PERFORMANCE SUMMARY\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "print(\"\\nüìä Accuracy Metrics:\")\n",
        "print(f\"  Training Accuracy:        {train_accs[-1]:.2f}%\")\n",
        "print(f\"  Validation Accuracy:      {val_accs[-1]:.2f}%\")\n",
        "print(f\"  Best Validation Accuracy: {best_val_acc:.2f}%\")\n",
        "print(f\"  Test Accuracy:            {test_accuracy:.2f}%\")\n",
        "\n",
        "print(\"\\nüéØ Model Characteristics:\")\n",
        "print(f\"  Total Parameters:         {sum(p.numel() for p in model.parameters()):,}\")\n",
        "print(f\"  Training Time:            {total_time/60:.1f} minutes\")\n",
        "print(f\"  Best Epoch:               {val_accs.index(max(val_accs)) + 1}/{num_epochs}\")\n",
        "print(f\"  Image Size:               {img_size}x{img_size}\")\n",
        "\n",
        "print(\"\\n‚ö†Ô∏è Overfitting Analysis:\")\n",
        "train_val_gap = train_accs[-1] - val_accs[-1]\n",
        "val_test_gap = val_accs[-1] - test_accuracy\n",
        "print(f\"  Train-Val Gap:            {train_val_gap:.2f}%\")\n",
        "print(f\"  Val-Test Gap:             {val_test_gap:.2f}%\")\n",
        "if train_val_gap > 20:\n",
        "    print(f\"  Status:                   ‚ö†Ô∏è  Significant overfitting detected\")\n",
        "elif train_val_gap > 10:\n",
        "    print(f\"  Status:                   ‚ö†Ô∏è  Moderate overfitting\")\n",
        "else:\n",
        "    print(f\"  Status:                   ‚úÖ Good generalization\")\n",
        "\n",
        "print(\"\\nüìÅ Saved Files:\")\n",
        "print(\"  - resnet50_animals10_best.pth\")\n",
        "print(\"  - resnet50_animals10_final.pth\")\n",
        "print(\"  - resnet50_training_history.png\")\n",
        "print(\"  - resnet50_confusion_matrix.png\")\n",
        "print(\"  - resnet50_per_class_accuracy.png\")\n",
        "print(\"  - resnet50_classification_report.txt\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"‚úÖ ANALYSIS COMPLETE!\")\n",
        "print(\"=\" * 70)\n"
      ],
      "metadata": {
        "id": "CZSLj0x7O7ls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "summary_text = f\"\"\"\n",
        "RESNET50 - ANIMALS10 CLASSIFICATION\n",
        "{'=' * 70}\n",
        "\n",
        "CONFIGURATION:\n",
        "- Architecture: ResNet-50 (from scratch)\n",
        "- Dataset: Animals10 (10 classes)\n",
        "- Total Images: {len(full_dataset)}\n",
        "- Train/Val/Test Split: 70%/15%/15%\n",
        "- Image Size: {img_size}x{img_size}\n",
        "- Batch Size: {batch_size}\n",
        "- Epochs: {num_epochs}\n",
        "- Learning Rate: {learning_rate}\n",
        "- Optimizer: SGD (momentum=0.9, weight_decay=1e-4)\n",
        "- Scheduler: CosineAnnealingLR\n",
        "\n",
        "PERFORMANCE RESULTS:\n",
        "- Final Training Accuracy:    {train_accs[-1]:.2f}%\n",
        "- Final Validation Accuracy:  {val_accs[-1]:.2f}%\n",
        "- Best Validation Accuracy:   {best_val_acc:.2f}%\n",
        "- Test Accuracy:              {test_accuracy:.2f}%\n",
        "\n",
        "MODEL STATISTICS:\n",
        "- Total Parameters: {sum(p.numel() for p in model.parameters()):,}\n",
        "- Training Time: {total_time/60:.1f} minutes\n",
        "- Best Epoch: {val_accs.index(max(val_accs)) + 1}/{num_epochs}\n",
        "\n",
        "OVERFITTING ANALYSIS:\n",
        "- Train-Val Gap: {train_val_gap:.2f}%\n",
        "- Val-Test Gap: {val_test_gap:.2f}%\n",
        "\n",
        "TOP 3 PERFORMING CLASSES:\n",
        "\"\"\"\n",
        "\n",
        "for i, (class_name, acc) in enumerate(best_classes[:3], 1):\n",
        "    summary_text += f\"{i}. {class_name}: {acc:.2f}%\\n\"\n",
        "\n",
        "summary_text += f\"\"\"\n",
        "BOTTOM 3 PERFORMING CLASSES:\n",
        "\"\"\"\n",
        "\n",
        "for i, (class_name, acc) in enumerate(reversed(best_classes[-3:]), 1):\n",
        "    summary_text += f\"{i}. {class_name}: {acc:.2f}%\\n\"\n",
        "\n",
        "summary_text += f\"\"\"\n",
        "MOST CONFUSED CLASS PAIRS:\n",
        "\"\"\"\n",
        "\n",
        "for i, (true_class, pred_class, count) in enumerate(confused_pairs[:5], 1):\n",
        "    summary_text += f\"{i}. {true_class} ‚Üí {pred_class}: {count} times\\n\"\n",
        "\n",
        "summary_text += f\"\"\"\n",
        "{'=' * 70}\n",
        "Analysis completed: {time.strftime('%Y-%m-%d %H:%M:%S')}\n",
        "\"\"\"\n",
        "\n",
        "# Save summary\n",
        "with open('resnet50_summary.txt', 'w') as f:\n",
        "    f.write(summary_text)\n",
        "\n",
        "print(\"\\n‚úÖ Complete summary saved to 'resnet50_summary.txt'\")\n",
        "print(\"\\nAll analysis complete! You now have comprehensive results for comparison with VGG16.\")"
      ],
      "metadata": {
        "id": "-vz9GXv3LIzf"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}