{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mel418/CECS456_project/blob/main/VGG16_Animals10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jn6YE7ouANkR"
      },
      "source": [
        "# VGG16 for Animals10 Classification\n",
        "\n",
        "**CECS 456 - Deep Learning Project**\n",
        "\n",
        "Melody Gatan\n",
        "\n",
        "**Dataset:** Animals10 (10 animal categories)\n",
        "\n",
        "**Model:** VGG16"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3vmN7GKANkU"
      },
      "source": [
        "## 1. Setup and Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FnzXcAIhANkU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# Check GPU availability\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using device: {device}')\n",
        "if device.type == 'cuda':\n",
        "    print(f'GPU: {torch.cuda.get_device_name(0)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IyhTFN43ANkV"
      },
      "source": [
        "## 2. Mount Google Drive and Setup Paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68mPhqLTANkV"
      },
      "outputs": [],
      "source": [
        "# Install kaggle and download dataset\n",
        "!pip install -q kaggle\n",
        "\n",
        "# Upload your kaggle.json file when prompted\n",
        "from google.colab import files\n",
        "files.upload()  # Upload kaggle.json\n",
        "\n",
        "# Setup kaggle credentials\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# Download and extract dataset\n",
        "!kaggle datasets download -d alessiocorrado99/animals10\n",
        "!unzip -q animals10.zip -d /content/animals10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2Z83bXoANkW"
      },
      "source": [
        "## 4. Custom Dataset Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_lCSsGZaANkW"
      },
      "outputs": [],
      "source": [
        "class Animals10Dataset(Dataset):\n",
        "    \"\"\"Custom dataset class for Animals10.\"\"\"\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.image_paths = []\n",
        "        self.labels = []\n",
        "\n",
        "        # Get class names from folder names\n",
        "        self.classes = sorted([d for d in os.listdir(root_dir)\n",
        "                              if os.path.isdir(os.path.join(root_dir, d))])\n",
        "        print(f\"Found classes: {self.classes}\")\n",
        "\n",
        "        # Load all image paths and labels\n",
        "        for idx, class_name in enumerate(self.classes):\n",
        "            class_path = os.path.join(root_dir, class_name)\n",
        "            for img_name in os.listdir(class_path):\n",
        "                if img_name.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    self.image_paths.append(os.path.join(class_path, img_name))\n",
        "                    self.labels.append(idx)\n",
        "\n",
        "        print(f\"Total images loaded: {len(self.image_paths)}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        try:\n",
        "            image = Image.open(img_path).convert('RGB')\n",
        "            if self.transform:\n",
        "                image = self.transform(image)\n",
        "            return image, label\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {img_path}: {e}\")\n",
        "            # Return a blank image if error occurs\n",
        "            return torch.zeros(3, 128, 128), label\n",
        "\n",
        "print(\"Dataset class defined!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class VGG16FromScratch(nn.Module):\n",
        "    \"\"\"VGG16 architecture trained from random initialization.\"\"\"\n",
        "\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(VGG16FromScratch, self).__init__()\n",
        "\n",
        "        # VGG16 Feature Extraction Layers\n",
        "        # All layers will be trained from scratch (no pretrained weights)\n",
        "        self.features = nn.Sequential(\n",
        "            # Block 1\n",
        "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),  # BatchNorm helps with scratch training\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            # Block 2\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            # Block 3\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            # Block 4\n",
        "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            # Block 5\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "\n",
        "        # Classifier Head\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512 * 4 * 4, 4096),  # 128x128 input -> 4x4 after pooling\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.Linear(4096, num_classes)\n",
        "        )\n",
        "\n",
        "        # Initialize all weights from scratch\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        \"\"\"Kaiming initialization for better training from scratch.\"\"\"\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, 0, 0.01)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "print(\"VGG16FromScratch model defined!\")"
      ],
      "metadata": {
        "id": "_f16AotTevWu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMlra6VnANkX"
      },
      "source": [
        "## 5. Data Transformations and Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B0psXk_1ANkX"
      },
      "outputs": [],
      "source": [
        "IMG_SIZE = 128\n",
        "\n",
        "# Training transformations (with data augmentation)\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Validation/Test transformations (no augmentation)\n",
        "val_test_transform = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "print(\"Data transformations defined!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djlef1fKANkX"
      },
      "source": [
        "## 6. Load and Split Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32vNEI7-ANkX"
      },
      "outputs": [],
      "source": [
        "# Dataset path\n",
        "dataset_path = '/content/animals10/raw-img'\n",
        "# Create full dataset\n",
        "print(\"Loading Animals10 dataset...\")\n",
        "full_dataset = Animals10Dataset(root_dir=dataset_path, transform=train_transform)\n",
        "\n",
        "# Split: 70% train, 15% validation, 15% test\n",
        "train_size = int(0.7 * len(full_dataset))\n",
        "val_size = int(0.15 * len(full_dataset))\n",
        "test_size = len(full_dataset) - train_size - val_size\n",
        "\n",
        "train_dataset, val_dataset, test_dataset = random_split(\n",
        "    full_dataset,\n",
        "    [train_size, val_size, test_size],\n",
        "    generator=torch.Generator().manual_seed(42)  # For reproducibility\n",
        ")\n",
        "\n",
        "# Apply appropriate transforms to validation and test sets\n",
        "val_dataset.dataset.transform = val_test_transform\n",
        "test_dataset.dataset.transform = val_test_transform\n",
        "\n",
        "print(f\"\\nðŸ“Š Dataset Split:\")\n",
        "print(f\"Training samples: {len(train_dataset)}\")\n",
        "print(f\"Validation samples: {len(val_dataset)}\")\n",
        "print(f\"Test samples: {len(test_dataset)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSP4jxazANkX"
      },
      "source": [
        "## 7. Create Data Loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cPlrjmK5ANkX"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=4,\n",
        "    pin_memory=True,\n",
        "    persistent_workers=True\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=4,\n",
        "    pin_memory=True,\n",
        "    persistent_workers=True\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=4,\n",
        "    pin_memory=True,\n",
        "    persistent_workers=True\n",
        ")\n",
        "\n",
        "print(f\"Batch size: {BATCH_SIZE}\")\n",
        "print(f\"Training batches: {len(train_loader)}\")\n",
        "print(f\"Validation batches: {len(val_loader)}\")\n",
        "print(f\"Test batches: {len(test_loader)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUBWmjdxANkY"
      },
      "source": [
        "## 8. Visualize Sample Images (Optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37AIo9VUANkY"
      },
      "outputs": [],
      "source": [
        "def imshow(img, title):\n",
        "    \"\"\"Display an image with title.\"\"\"\n",
        "    img = img / 2 + 0.5  # Unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.title(title)\n",
        "    plt.axis('off')\n",
        "\n",
        "# Get a batch of training images\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# Display 8 sample images\n",
        "fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    if i < len(images):\n",
        "        plt.sca(ax)\n",
        "        imshow(images[i].cpu(), f\"Class: {full_dataset.classes[labels[i]]}\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create model (FROM SCRATCH - NO PRETRAINED WEIGHTS)\n",
        "model = VGG16FromScratch(num_classes=10).to(device)\n",
        "\n",
        "# Count parameters\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f\"\\nðŸ”§ Model Architecture: VGG16 (From Scratch)\")\n",
        "print(f\"Total parameters: {total_params:,}\")\n",
        "print(f\"Trainable parameters: {trainable_params:,}\")\n",
        "print(f\"Training approach: All layers trained from random initialization\")\n",
        "print(f\"Image size: {IMG_SIZE}x{IMG_SIZE}\")"
      ],
      "metadata": {
        "id": "JV5C42pgimUE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GL-fNdOMANkY"
      },
      "source": [
        "## 10. Training Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8YbXFHJiANkZ"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(model, loader, criterion, optimizer, device):\n",
        "    \"\"\"Train for one epoch.\"\"\"\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    pbar = tqdm(loader, desc='Training')\n",
        "    for images, labels in pbar:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Statistics\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "        # Update progress bar\n",
        "        pbar.set_postfix({\n",
        "            'loss': f'{loss.item():.4f}',\n",
        "            'acc': f'{100.*correct/total:.2f}%'\n",
        "        })\n",
        "\n",
        "    epoch_loss = running_loss / len(loader)\n",
        "    epoch_acc = 100 * correct / total\n",
        "\n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "\n",
        "def validate(model, loader, criterion, device):\n",
        "    \"\"\"Validate the model.\"\"\"\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(loader, desc='Validation'):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(loader)\n",
        "    epoch_acc = 100 * correct / total\n",
        "\n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "print(\"Training functions defined!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQcAe5YHANkZ"
      },
      "source": [
        "## 11. Training Configuration and Main Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LusKgJOkANkZ"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "EPOCHS = 15  # More epochs needed for training from scratch\n",
        "LEARNING_RATE = 0.01  # Higher learning rate for scratch training\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=0.9, weight_decay=1e-4)\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"TRAINING CONFIGURATION\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Epochs: {EPOCHS}\")\n",
        "print(f\"Batch Size: {BATCH_SIZE}\")\n",
        "print(f\"Learning Rate: {LEARNING_RATE}\")\n",
        "print(f\"Optimizer: SGD (momentum=0.9)\")\n",
        "print(f\"Scheduler: CosineAnnealingLR\")\n",
        "print(f\"Target: 50-70% accuracy (training from scratch)\")\n",
        "print(\"=\" * 60)\n",
        "# For tracking metrics\n",
        "history = {\n",
        "    'train_loss': [],\n",
        "    'train_acc': [],\n",
        "    'val_loss': [],\n",
        "    'val_acc': []\n",
        "}\n",
        "\n",
        "best_val_acc = 0.0\n",
        "\n",
        "print(\"\\nðŸš€ Starting Training...\")\n",
        "print(\"=\" * 60)\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    print(f\"\\nEpoch [{epoch+1}/{EPOCHS}]\")\n",
        "\n",
        "    # Train\n",
        "    train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
        "\n",
        "    # Validate\n",
        "    val_loss, val_acc = validate(model, val_loader, criterion, device)\n",
        "\n",
        "    # Update learning rate\n",
        "    scheduler.step()\n",
        "\n",
        "    # Save metrics\n",
        "    history['train_loss'].append(train_loss)\n",
        "    history['train_acc'].append(train_acc)\n",
        "    history['val_loss'].append(val_loss)\n",
        "    history['val_acc'].append(val_acc)\n",
        "\n",
        "    # Print summary\n",
        "    print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
        "    print(f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    # Save best model\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        torch.save(model.state_dict(), 'vgg16_scratch_best.pth')\n",
        "        print(f\"âœ“ Best model saved! Val Acc: {val_acc:.2f}%\")\n",
        "\n",
        "total_time = time.time() - start_time\n",
        "\n",
        "print(f\"\\nâœ… Training Complete!\")\n",
        "print(f\"Total training time: {total_time:.2f} seconds ({total_time/60:.2f} minutes)\")\n",
        "print(f\"Best validation accuracy: {best_val_acc:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKwFv78AANka"
      },
      "source": [
        "## 12. Plot Training History"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IOi7eY40ANka"
      },
      "outputs": [],
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Loss plot\n",
        "ax1.plot(history['train_loss'], label='Train Loss', marker='o')\n",
        "ax1.plot(history['val_loss'], label='Val Loss', marker='s')\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_ylabel('Loss')\n",
        "ax1.set_title('Training and Validation Loss')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Accuracy plot\n",
        "ax2.plot(history['train_acc'], label='Train Accuracy', marker='o')\n",
        "ax2.plot(history['val_acc'], label='Val Accuracy', marker='s')\n",
        "ax2.set_xlabel('Epoch')\n",
        "ax2.set_ylabel('Accuracy (%)')\n",
        "ax2.set_title('Training and Validation Accuracy')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('vgg16_scratch_training_history.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulTGzK9jANka"
      },
      "source": [
        "## 13. Test Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zSROygYZANka"
      },
      "outputs": [],
      "source": [
        "def test_model(model, test_loader):\n",
        "    \"\"\"Test the model and return predictions.\"\"\"\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(test_loader, desc='Testing'):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    test_acc = 100 * correct / total\n",
        "    return all_preds, all_labels, test_acc\n",
        "\n",
        "print(\"ðŸ§ª Testing Model...\")\n",
        "predictions, true_labels, test_accuracy = test_model(model, test_loader)\n",
        "print(f\"\\nðŸ“Š Test Accuracy: {test_accuracy:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89pXEjiuANkb"
      },
      "source": [
        "## 14. Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fr0l72cpANkb"
      },
      "outputs": [],
      "source": [
        "class_names = full_dataset.classes\n",
        "cm = confusion_matrix(true_labels, predictions)\n",
        "\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=class_names, yticklabels=class_names,\n",
        "            cbar_kws={'label': 'Count'})\n",
        "plt.xlabel('Predicted Label', fontsize=12)\n",
        "plt.ylabel('True Label', fontsize=12)\n",
        "plt.title('VGG16 From Scratch - Confusion Matrix', fontsize=14, fontweight='bold')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.yticks(rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.savefig('vgg16_scratch_confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# Identify most confused pairs\n",
        "print(\"\\nðŸ” Most Confused Classes:\")\n",
        "for i in range(len(class_names)):\n",
        "    for j in range(len(class_names)):\n",
        "        if i != j and cm[i][j] > 5:\n",
        "            print(f\"  {class_names[i]} â†’ {class_names[j]}: {cm[i][j]} times\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SY0dQFvOANkb"
      },
      "source": [
        "## 15. Classification Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ugDa5NnANkb"
      },
      "outputs": [],
      "source": [
        "print(\"\\nðŸ“‹ Classification Report:\")\n",
        "print(\"=\" * 70)\n",
        "report = classification_report(true_labels, predictions,\n",
        "                                target_names=class_names,\n",
        "                                digits=3)\n",
        "print(report)\n",
        "\n",
        "# Save report\n",
        "with open('vgg16_scratch_classification_report.txt', 'w') as f:\n",
        "    f.write(report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVj4BSqaANkb"
      },
      "source": [
        "## 16. Per-Class Accuracy Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_kcf1d1ANkc"
      },
      "outputs": [],
      "source": [
        "# Calculate per-class accuracy\n",
        "class_correct = [0] * len(class_names)\n",
        "class_total = [0] * len(class_names)\n",
        "\n",
        "for pred, true in zip(predictions, true_labels):\n",
        "    class_total[true] += 1\n",
        "    if pred == true:\n",
        "        class_correct[true] += 1\n",
        "\n",
        "class_accuracy = [100 * c / t if t > 0 else 0\n",
        "                  for c, t in zip(class_correct, class_total)]\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(12, 6))\n",
        "bars = plt.bar(class_names, class_accuracy, color='skyblue', edgecolor='navy')\n",
        "plt.axhline(y=test_accuracy, color='r', linestyle='--',\n",
        "            label=f'Overall Accuracy: {test_accuracy:.2f}%')\n",
        "plt.xlabel('Animal Class', fontsize=12)\n",
        "plt.ylabel('Accuracy (%)', fontsize=12)\n",
        "plt.title('VGG16 From Scratch - Per-Class Accuracy', fontsize=14, fontweight='bold')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.ylim([0, 105])\n",
        "plt.legend()\n",
        "plt.grid(axis='y', alpha=0.3)\n",
        "\n",
        "# Add value labels on bars\n",
        "for bar, acc in zip(bars, class_accuracy):\n",
        "    height = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2., height,\n",
        "             f'{acc:.1f}%', ha='center', va='bottom', fontsize=9)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('vgg16_scratch_per_class_accuracy.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pl8vTMxeANkc"
      },
      "source": [
        "## 17. Save Model and Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F7mhHAZRANkc"
      },
      "outputs": [],
      "source": [
        "print(f\"\\n\" + \"=\" * 70)\n",
        "print(\"FINAL RESULTS SUMMARY\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"Model: VGG16 (From Scratch - No Transfer Learning)\")\n",
        "print(f\"Dataset: Animals10 ({len(full_dataset)} images)\")\n",
        "print(f\"Classes: {len(class_names)}\")\n",
        "print(f\"Image Size: {IMG_SIZE}x{IMG_SIZE}\")\n",
        "print(f\"\\nTraining Configuration:\")\n",
        "print(f\"  Epochs: {EPOCHS}\")\n",
        "print(f\"  Batch Size: {BATCH_SIZE}\")\n",
        "print(f\"  Learning Rate: {LEARNING_RATE}\")\n",
        "print(f\"  Optimizer: SGD (momentum=0.9)\")\n",
        "print(f\"\\nResults:\")\n",
        "print(f\"  Test Accuracy: {test_accuracy:.2f}%\")\n",
        "print(f\"  Best Validation Accuracy: {best_val_acc:.2f}%\")\n",
        "print(f\"  Total Training Time: {total_time/60:.2f} minutes\")\n",
        "print(f\"\\nTotal Parameters: {total_params:,}\")\n",
        "print(f\"All parameters trained from random initialization\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Save model\n",
        "torch.save(model.state_dict(), 'vgg16_scratch_final.pth')\n",
        "print(\"\\nâœ… Model saved: vgg16_scratch_final.pth\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}